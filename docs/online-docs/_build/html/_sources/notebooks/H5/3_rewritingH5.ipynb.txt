{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rewrite_H5.py\n",
    "## 1. Introduction\n",
    "\n",
    "The COMPAS simulations might be very large in data size while the actual data you need to reproduce your",
    " results could be small, so it might make sense to reduce the number of files and columns based on some",
    " criteria.\n",
    "\n",
    "Here we show how you can reduce your data. The main things you need are:\n",
    "\n",
    "1 - The seeds you want to have in your data.\n",
    "\n",
    "2 - The files you want in your data.\n",
    "\n",
    "3 - The columns (parameters) you want for each file.\n",
    "\n",
    "The plain Python script to do this is `$COMPAS_ROOT_DIR/postProcessing/Folders/H5/rewrite_H5.py`. Here we just",
    " show an example of how to call the script in order to reduce the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Paths needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the appropriate paths to the input and output data files\n",
    "\n",
    "pathToDataInput  = '../COMPAS_Output.h5'         \n",
    "pathToDataOutput = '../COMPAS_Output_reduced.h5' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py  as h5  # For handling data format\n",
    "import sys\n",
    "\n",
    "# Import the rewrite_H5.py script\n",
    "sys.path.append('PythonScripts/')\n",
    "import rewrite_H5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data  = h5.File(pathToDataInput)\n",
    "print(\"The main files I have at my disposal are:\\n\",list(Data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the parameter choices in each file, use, e.g:\n",
    "#print(list(Data['BSE_System_Parameters']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Specify which files and columns you want\n",
    "\n",
    "We use dictionaries to specifically link all the entries:\n",
    "\n",
    "- The `filesOfInterest` dictionary should contain all files which hold any relevant data.\n",
    "\n",
    "- The `columnsOfInterest` dictionary specifies the parameters in each file that you want to be included in the new",
    " output HDF5 file.\n",
    "\n",
    "- Any filters or masks should be used to determine the `seedsOfInterest` (on a per file basis), and so do not need",
    " to be included in the `columnsOfInterest` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Hypothetical example\n",
    "\n",
    "Suppose you are studying double neutron star (DNS) systems, and you want to know the initial parameters of both",
    " components. Suppose you are separately curious about the eccentricity of systems following a supernova (SN) that",
    " leaves the binary intact, and you want to use the same COMPAS run to save on CPU hours.\n",
    "\n",
    "- To be safe, you should probably keep the entire `BSE_System_Parameters` file, which contains all of the initial",
    " system settings.\n",
    "\n",
    "- To get information about only DNSs, you will need to create a mask for them from the `BSE_Double_Compact_Objects` file.\n",
    "\n",
    "- Information on post-SN eccentricity and whether or not the system disrupted is found in the `BSE_Supernovae` file.\n",
    "\n",
    "You will not need any other files. You will also want to grab the 'SEED' column from any file, since the seed is the",
    " unique identifier of each binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which files do you want?\n",
    "filesOfInterest   = {1:'BSE_System_Parameters',\\\n",
    "                     2:'BSE_Double_Compact_Objects',\\\n",
    "                     3:'BSE_Supernovae'}\n",
    "\n",
    "# Give a list of columns you want, if you want all, say ['All']\n",
    "columnsOfInterest = {1:['All'],\\\n",
    "                     2:['All'],\\\n",
    "                     3:['SEED', 'Eccentricity']}\n",
    "\n",
    "# The seedsOfInterest are a little more involved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Which seeds do I want per file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not filter out any systems/seeds from SystemParameters\n",
    "\n",
    "seedsSystems = Data['BSE_System_Parameters']['SEED'][()]\n",
    "\n",
    "\n",
    "\n",
    "### Of all the double compact objects, keep only the DNSs\n",
    "\n",
    "DCOs = Data['BSE_Double_Compact_Objects']\n",
    "seedsDCOs       =  DCOs['SEED'][()]\n",
    "\n",
    "typePrimary     =  DCOs['Stellar_Type(1)'][()]\n",
    "typeSecondary   =  DCOs['Stellar_Type(2)'][()]\n",
    "DNSs            =  (typePrimary == 13) & (typeSecondary == 13)\n",
    "\n",
    "seedsDNS        =  seedsDCOs[DNSs]\n",
    "\n",
    "\n",
    "\n",
    "### Filter out disrupted systems\n",
    "\n",
    "SNe  = Data['BSE_Supernovae']\n",
    "seedsSNe     = SNe['SEED']\n",
    "\n",
    "\n",
    "isUnbound    = SNe['Unbound'][()] \n",
    "intact       = (isUnbound == False)\n",
    "\n",
    "seedsIntact  = seedsSNe[intact]\n",
    "\n",
    "\n",
    "\n",
    "### Create seedsOfInterest dictionary -- DOUBLE CHECK ORDER :) \n",
    "\n",
    "seedsOfInterest   = {1:seedsSystems,\\\n",
    "                     2:seedsDCOs,\\\n",
    "                     3:seedsIntact}\n",
    "\n",
    "\n",
    "# Don't forget to close the original h5 data file\n",
    "Data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Call the function that creates the HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_H5.reduceH5(pathToOld = pathToDataInput, pathToNew = pathToDataOutput,\\\n",
    "                     dictFiles=filesOfInterest, dictColumns=columnsOfInterest, dictSeeds=seedsOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rewrite_H5.printAllColumnsInH5(pathToDataOutput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
